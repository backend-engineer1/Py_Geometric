from typing import List, Tuple, Optional, NamedTuple

import torch
from torch import Tensor
import torch_sparse
from torch_sparse import SparseTensor
from torch_geometric.typing import Size
from torch_geometric.nn.conv.message_passing import *
from {{module}} import *

class Propagate_{{uid}}(NamedTuple):
{% for k, v in prop_dict.items() %}
    {{k}}: {{v}}
{% endfor %}

class Collect_{{uid}}(NamedTuple):
{% for k, v in collect_dict.items() %}
    {{k}}: {{v}}
{% endfor %}



class {{clsname}}Jittable_{{uid}}({{clsname}}):

    @torch.jit._overload_method
    def __check_input__(self, edge_index, size):
        # type: (Tensor, Size) -> List[Optional[int]]
        pass

    @torch.jit._overload_method
    def __check_input__(self, edge_index, size):
        # type: (SparseTensor, Size) -> List[Optional[int]]
        pass

{{check_input}}

    @torch.jit._overload_method
    def __lift__(self, src, edge_index, dim):
        # type: (Tensor, Tensor, int) -> Tensor
        pass

    @torch.jit._overload_method
    def __lift__(self, src, edge_index, dim):
        # type: (Tensor, SparseTensor, int) -> Tensor
        pass

{{lift}}

    @torch.jit._overload_method
    def __collect__(self, edge_index, size, kwargs):
        # type: (Tensor, List[Optional[int]], Propagate_{{uid}}) -> Collect_{{uid}}
        pass

    @torch.jit._overload_method
    def __collect__(self, edge_index, size, kwargs):
        # type: (SparseTensor, List[Optional[int]], Propagate_{{uid}}) -> Collect_{{uid}}
        pass

    def __collect__(self, edge_index, size, kwargs):
        # TODO
        x_j: torch.Tensor = torch.tensor(0)
        data = kwargs.x
        if isinstance(data, (tuple, list)):
            assert len(data) == 2
            tmp = data[1]
            if isinstance(tmp, Tensor):
                self.__set_size__(size, 1, tmp)
            x_j = data[0]
        else:
            x_j = data
        if isinstance(data, Tensor):
            self.__set_size__(size, dim, data)
            x_j = self.__lift__(data, edge_index, dim)
        x = kwargs.x
        i, j = 0, 1
        ptr: Optional[Tensor] = None
        if isinstance(edge_index, Tensor):
            edge_index_j = edge_index[j]
            edge_index_i = edge_index[i]
        elif isinstance(edge_index, SparseTensor):
            edge_index_j = edge_index.storage.col()
            edge_index_i = edge_index.storage.row()
            ptr = edge_index.storage.rowptr()
            edge_attr = edge_index.storage.value()
            edge_weight = edge_index.storage.value()

        index = edge_index_i
        size_j = size[j]
        size_i = size[i]
        if size_j is None:
            size_j = size_i
        if size_i is None:
            size_i = size_j
        dim_size = size_i
        return Collect_{{uid}}(dim_size=dim_size, ptr=ptr, index=index, x_j=x_j, x=x)

    @torch.jit._overload_method
    def propagate(self, edge_index, {% for k in prop_dict.keys() %}{{k}}, {% endfor %}size=None):
        # type: (Tensor, {% for v in prop_dict.values() %}{{v}}, {% endfor %}Size) -> Tensor
        pass

    @torch.jit._overload_method
    def propagate(self, edge_index, {% for k in prop_dict.keys() %}{{k}}, {% endfor %}size=None):
        # type: (SparseTensor, {% for v in prop_dict.values() %}{{v}}, {% endfor %}Size) -> Tensor
        pass

    def propagate(self, edge_index, {% for k in prop_dict.keys() %}{{k}}, {% endfor %}size=None):
        the_size = self.__check_input__(edge_index, size)
        in_kwargs = Propagate_{{uid}}({% for k in prop_dict.keys() %}{{k}}{{ ", " if not loop.last }}{% endfor %})
        kwargs = self.__collect__(edge_index, the_size, in_kwargs)

        if self.fuse:
            if isinstance(edge_index, SparseTensor):
                out = self.message_and_aggregate(edge_index{% for k in msg_and_aggr_args %}, {{k}}=kwargs.{{k}}{% endfor %})
                return self.update(out{% for k in update_args %}, {{k}}=kwargs.{{k}}{% endfor %})

        out = self.message({% for k in msg_args %}{{k}}=kwargs.{{k}}{{ ", " if not loop.last }}{% endfor %})
        out = self.aggregate(out{% for k in aggr_args %}, {{k}}=kwargs.{{k}}{% endfor %})
        return self.update(out{% for k in update_args %}, {{k}}=kwargs.{{k}}{% endfor %})

{% for t in forward_types %}
    @torch.jit._overload_method
{{forward_header}}:
{{t}}
        pass
{% endfor %}

{{forward_header}}:
{{forward_body}}
